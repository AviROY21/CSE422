# -*- coding: utf-8 -*-
"""Final_422lab_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lsbm3rOxFa6DLWMD_3q9sp-C3gurOhcj
"""

from google.colab import drive
drive.mount('/content/drive')

"""# `Neccessary Libaries `"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

"""**PRE-PROCESSING**
*   Null value: 0
*   Duplicate: 0



"""

initial_dataset = pd.read_csv('/content/drive/MyDrive/datasets/new_model.csv')
initial_dataset.head()

initial_dataset.info()

initial_dataset.isnull().sum()

initial_dataset[initial_dataset.duplicated()]

initial_dataset.shape  #shows (row and column) size in dataset

#statistical measures about the data
initial_dataset.describe()

for item in initial_dataset.columns:
    print(item,"=>",len(initial_dataset[item].unique()))

"""## Visualisation of dataset



> Feature and label







"""

col = ["Bu","Sc","Pot","Hemo","Wbcc","Rbcc","Class"] # Pairplot figure to show correlation betweean features
sns.pairplot(initial_dataset[col],hue="Class")

# Using Heatmap to show correlation between features
features = initial_dataset.drop(initial_dataset.columns[-1],axis=1) # drop 'Class' column- not a feature 
fig = plt.figure(figsize=(10, 10))
corr_plot = sns.heatmap(features.corr(),annot = True, cmap = 'rainbow' )
plt.title("Data Correlation plot")
plt.show()

#checking the distribution
initial_dataset["Class"].value_counts()
#0---- Healthy Kidney
#1-----defected kidney

"""## SPLIT DATA AND TRAIN"""

X = initial_dataset.drop(['Class'], axis = 1)
Y = initial_dataset[['Class']]

X.info()

Y.info()

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state=1)
print(X.shape,X_train.shape,X_test.shape)

"""## Logistic regression"""

from sklearn.linear_model import LogisticRegression
LR_model=LogisticRegression(random_state=1, solver='lbfgs',multi_class='auto', max_iter=500)
LR_model.fit(X_train,Y_train.values.ravel())

x=LR_model.predict(X_test)
x

s=LR_model.score(X_test,Y_test)
LR=s*100
print('Logistic Regression accuracy:', s*100)

from sklearn.metrics import confusion_matrix,classification_report
plt.figure()
sns.heatmap(confusion_matrix(Y_test, x), annot=True)
plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.title("Logistic Regression Confusion Matrix");

"""# Decision tree classifier"""

from sklearn.tree import DecisionTreeClassifier
clf= DecisionTreeClassifier()
clf.fit(X_train,Y_train)
clf.score(X_test,Y_test)
score = clf.score(X_test,Y_test)
DTC = score*100
print("Decision Tree Classifier Accuracy :", score*100)

"""# Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
RF= RandomForestClassifier()
RF.fit(X_train,Y_train)

RF.score(X_train,Y_train)

RF.score(X_test,Y_test)
RFC= RF.score(X_test,Y_test)*100

from sklearn.metrics import confusion_matrix,classification_report
plt.figure()
sns.heatmap(confusion_matrix(Y_test, x), annot=True)
plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.title("Random Forest Classifier Confusion Matrix");

"""## KNeighbors classifier"""

from sklearn.neighbors import KNeighborsClassifier
KNN_model = KNeighborsClassifier(n_neighbors=3) 
KNN_model.fit(features,Y.values.ravel())

s=KNN_model.score(features,Y)
KNN=s*100
print('KNeighborsClassifier accuracy:', s*100)

x=KNN_model.predict(X_test)
x

from sklearn.metrics import confusion_matrix,classification_report
plt.figure()
sns.heatmap(confusion_matrix(Y_test, x), annot=True)
plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.title("K Neighbors Classifier Confusion Matrix");

"""## Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
NB_model = GaussianNB()
NB_model.fit(X_train,Y_train.values.ravel())

score = NB_model.score(X_test,Y_test)
NB=score*100
print("Naive Bayes Accuracy :", score*100)

x=NB_model.predict(X_test)
x

from sklearn.metrics import confusion_matrix,classification_report
plt.figure()
sns.heatmap(confusion_matrix(Y_test, x), annot=True)
plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.title("Naive Bayes Confusion Matrix");

"""# Analysis

"""

plt.figure(figsize=(12,12))
col=[LR,RFC,KNN,NB]
name=['LR','RFC','KNN','NB']
print('Highest accuracy:',max(col),'(',name[col.index(max(col))],'Model )\n')
plt.pie(col,labels=name,autopct='%.2f%%')
plt.legend(col)
plt.show()

from sklearn.model_selection import cross_val_score
algorithms = [LR_model,KNN_model,RF,NB_model]
for alg in algorithms:
    accuracies = cross_val_score(estimator=alg, X=features, y=Y, cv=10)
    print("{0}: \t {1}".format(alg,accuracies.mean()))